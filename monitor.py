import requests
import re
import xml.etree.ElementTree as ET
from datetime import datetime
# /// script
# requires-python = ">=3.9"
# dependencies = [
#     "requests",
# ]
# ///
def get_channel_id_from_url(url):
    """
    å¾ YouTube é »é“ URL æå– Channel IDã€‚
    å¦‚æœæ˜¯ @Handle URL æˆ– /channel/ URLï¼Œå˜—è©¦å¾é é¢å…§å®¹æå– channel_idã€‚
    """
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        response.raise_for_status()
        
        # å˜—è©¦å¤šç¨®æ­£å‰‡è¡¨é”å¼ä¾†å°‹æ‰¾ Channel ID
        patterns = [
            r'itemprop="channelId" content="([^"]+)"',  # meta tag
            r'"channelId":"([^"]+)"',                    # JSON config
            r'"externalId":"([^"]+)"',                   # JSON config
            r'"browseId":"(UC[^"]+)"',                   # ytInitialData (Channel IDs start with UC)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response.text)
            if match:
                return match.group(1)
            
        print(f"âš ï¸ ç„¡æ³•å¾ {url} æå– Channel ID")
        return None
    except Exception as e:
        print(f"âŒ ç²å– {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
def get_latest_video(channel_id):
    """
    ä½¿ç”¨ RSS Feed ç²å–æœ€æ–°å½±ç‰‡è³‡è¨Š (è‡ªå‹•è·³é Shorts)
    """
    rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
    try:
        response = requests.get(rss_url)
        response.raise_for_status()
        
        root = ET.fromstring(response.content)
        
        # XML Namespace (Atom)
        ns = {'atom': 'http://www.w3.org/2005/Atom', 'yt': 'http://www.youtube.com/xml/schemas/2015'}
        
        # éæ­·æ‰€æœ‰ entries å°‹æ‰¾ç¬¬ä¸€å€‹é Shorts çš„å½±ç‰‡
        for entry in root.findall('atom:entry', ns):
            link = entry.find('atom:link', ns).attrib['href']
            
            # æª¢æŸ¥æ˜¯å¦ç‚º Shorts
            if '/shorts/' in link:
                continue

            title = entry.find('atom:title', ns).text
            published = entry.find('atom:published', ns).text
            # ç°¡å–®æ ¼å¼åŒ–æ™‚é–“ (ç§»é™¤æ™‚å€è³‡è¨Šä»¥ä¾¿é–±è®€ï¼Œæˆ–ä¿ç•™)
            # æ ¼å¼ç¯„ä¾‹: 2025-01-13T12:00:00+00:00
            
            return {
                'title': title,
                'link': link,
                'published': published
            }
        
        return None
    except Exception as e:
        print(f"âŒ ç²å– RSS {channel_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
def main():
    channels = [
        "https://www.youtube.com/@LennysPodcast",
        "https://www.youtube.com/@googleantigravity",
        "https://www.youtube.com/@Google/videos",
        "https://www.youtube.com/@ycombinator",
        "https://www.youtube.com/@a16z",
        "https://www.youtube.com/@aiDotEngineer"
    ]
    print(f"é–‹å§‹æª¢æŸ¥ {len(channels)} å€‹é »é“...\n")
    for url in channels:
        print(f"æ­£åœ¨æª¢æŸ¥: {url} ...")
        channel_id = get_channel_id_from_url(url)
        
        if channel_id:
            # print(f"  -> Channel ID: {channel_id}") # Debug usage
            video_info = get_latest_video(channel_id)
            
            if video_info:
                print(f"  âœ… æœ€æ–°å½±ç‰‡: {video_info['title']}")
                print(f"  ğŸ“… ç™¼å¸ƒæ™‚é–“: {video_info['published']}")
                print(f"  ğŸ”— é€£çµ: {video_info['link']}")
            else:
                print("  âš ï¸ å°šç„¡å½±ç‰‡æˆ–ç„¡æ³•è§£æ RSS")
        
        print("-" * 50)
if __name__ == "__main__":
    main()
